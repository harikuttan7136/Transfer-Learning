{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import math\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils,io,datasets\n",
    "import torch.utils.data as data_utils\n",
    "from torch.optim import SGD,Adam,lr_scheduler\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootDir=\"group_3/\"\n",
    "trainDir=\"train\"\n",
    "valDir=\"valididation\"\n",
    "testDir=\"test\"\n",
    "batchSize=128\n",
    "device=torch.device(\"cuda:2\")\n",
    "p=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class CustomTensorDataset(Dataset):\\n    def __init__(self, tensors, transform=None):\\n        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\\n        self.tensors = tensors\\n        self.transform = transform\\n\\n    def __getitem__(self, index):\\n        x = self.tensors[0][index]\\n\\n        if self.transform:\\n            x = self.transform(x)\\n\\n        y = self.tensors[1][index]\\n\\n        return x, y\\n\\n    def __len__(self):\\n        return self.tensors[0].size(0)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"class CustomTensorDataset(Dataset):\n",
    "    def __init__(self, tensors, transform=None):\n",
    "        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n",
    "        self.tensors = tensors\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.tensors[0][index]\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        y = self.tensors[1][index]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.tensors[0].size(0)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(dataset,typeData=\"train\"):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    data=dataset[typeData][\"image\"]\n",
    "    label=dataset[typeData][\"label\"]\n",
    "    for i in range(len(data)):\n",
    "        img=np.array(data[i])\n",
    "        if img.ndim==3:\n",
    "            X.append(img)\n",
    "            Y.append(label[i])\n",
    "    return torch.tensor(np.array(X)),torch.tensor(np.array(Y).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self, n_in, n_out,modelVGGFeatureMap,avgPool ,layers,activationFn=torch.nn.ReLU() ,dropout=False,BN=False):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.modelVGGFeatureMap=modelVGGFeatureMap\n",
    "        self.avgPool=avgPool        \n",
    "        net=[]\n",
    "        for i in range(len(layers)-2):\n",
    "            net.append(torch.nn.Linear(layers[i],layers[i+1]))\n",
    "            if BN and i==0:\n",
    "                net.append(torch.nn.BatchNorm1d(layers[i+1]))\n",
    "            net.append(activationFn)\n",
    "            if dropout and i==0:\n",
    "                net.append(torch.nn.Dropout(p))\n",
    "\n",
    "        net.append(torch.nn.Linear(layers[-2],layers[-1]))\n",
    "        self.fc = torch.nn.Sequential(*net)\n",
    "        \n",
    "\n",
    "    def forward(self, X):\n",
    "        features=self.modelVGGFeatureMap(X)\n",
    "        features=self.avgPool(features)\n",
    "        features=features.reshape(features.shape[0],-1)\n",
    "        \n",
    "        output=self.fc(features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model,epochs=30, returnLoss=False, returnAccuracy=False , saveModelName=\"bestModel\"):\n",
    "    epoch_step_size=1\n",
    "    bestValidAccuracy=-1\n",
    "    \n",
    "    lossList=[]\n",
    "    trainaccuracyList=[]\n",
    "    validaccuracyList=[]\n",
    "    \n",
    "    print(\"Started training the network\")\n",
    "    startTime=time.time()\n",
    "    for epoch in range(epochs):\n",
    "        print()\n",
    "        print(\"Starting epoch no \",str(epoch))\n",
    "        model.train()\n",
    "        runningLoss=0\n",
    "        for batch_idx, (trainData, trainTarget) in enumerate(trainLoader):\n",
    "            #l1Norm=0\n",
    "            optimizer.zero_grad()\n",
    "            trainData, trainTarget = trainData.to(device), trainTarget.reshape(-1).type(torch.LongTensor).to(device)\n",
    "            output = model(trainData)\n",
    "            loss = lossFn(output, trainTarget)\n",
    "            #if epoch>6:\n",
    "            #     l1Norm = 0.01*sum(torch.linalg.norm(p, 2) for p in model.fc.parameters())\n",
    "            \n",
    "            loss=loss#+l1Norm\n",
    "            loss.backward()\n",
    "            optimizer.step()    \n",
    "            runningLoss+=loss.item()\n",
    "        \n",
    "        trainAccuracy=findAccuracy(model,trainLoader)\n",
    "        validAccuracy=findAccuracy(model,validLoader)\n",
    "        \n",
    "        if returnLoss:\n",
    "            lossList.append(runningLoss)\n",
    "        \n",
    "        if returnAccuracy:\n",
    "            trainaccuracyList.append(trainAccuracy)\n",
    "            validaccuracyList.append(validAccuracy)\n",
    "            \n",
    "        if validAccuracy>bestValidAccuracy:\n",
    "            print(\"Saving the model\")\n",
    "            torch.save(model.state_dict(), saveModelName+'.pth')\n",
    "            bestValidAccuracy=validAccuracy\n",
    "            \n",
    "        scheduler.step()\n",
    "        if epoch%epoch_step_size==0:\n",
    "            print(\"Loss: \",str(runningLoss)+\" Train Accuracy is \",str(trainAccuracy)+\" Valid Accuracy is \",str(validAccuracy))\n",
    "    \n",
    "    model.load_state_dict(torch.load(saveModelName+\".pth\"))\n",
    "    endTime=time.time()\n",
    "    print(\"Training finished in \",str(endTime-startTime)+\" seconds\")\n",
    "    return model,lossList, trainaccuracyList, validaccuracyList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAccuracy(model,loader):\n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "  \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images,labels) in enumerate(loader):\n",
    "            images,labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            Ypred = torch.argmax(outputs, 1)\n",
    "            total += images.size(0)\n",
    "            accuracy += (Ypred.reshape(-1) == labels.reshape(-1)).sum().item()\n",
    "    accuracy = (100 * accuracy / total)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = load_dataset(\"imagefolder\", data_dir=rootDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trainPreprocess = transform =   transforms.Compose([\\n        #transforms.Resize((224, 224)),\\n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\\n        transforms.RandomHorizontalFlip(),\\n        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\\n        transforms.RandomAffine(degrees=15, translate=None, scale=(1, 2), shear=5, resample=False, fillcolor=0),\\n        \\n])\\n\\n\\ntestPreprocess = transform =   transforms.Compose([\\n        #transforms.Resize((224, 224)),\\n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))        \\n])'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"trainPreprocess = transform =   transforms.Compose([\n",
    "        #transforms.Resize((224, 224)),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "        transforms.RandomAffine(degrees=15, translate=None, scale=(1, 2), shear=5, resample=False, fillcolor=0),\n",
    "        \n",
    "])\n",
    "\n",
    "\n",
    "testPreprocess = transform =   transforms.Compose([\n",
    "        #transforms.Resize((224, 224)),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))        \n",
    "])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensorXtrain,tensorYtrain=loadData(dataset)\\ntensorXtest,tensorYtest=loadData(dataset,typeData=\"test\")\\ntensorXvalid,tensorYvalid=loadData(dataset,typeData=\"validation\")'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"tensorXtrain,tensorYtrain=loadData(dataset)\n",
    "tensorXtest,tensorYtest=loadData(dataset,typeData=\"test\")\n",
    "tensorXvalid,tensorYvalid=loadData(dataset,typeData=\"validation\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensorXtrain=tensorXtrain.reshape(tensorXtrain.shape[0],3,224,224)/255\\ntensorXtest=tensorXtest.reshape(tensorXtest.shape[0],3,224,224)/255\\ntensorXvalid=tensorXvalid.reshape(tensorXvalid.shape[0],3,224,224)/255\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"tensorXtrain=tensorXtrain.reshape(tensorXtrain.shape[0],3,224,224)/255\n",
    "tensorXtest=tensorXtest.reshape(tensorXtest.shape[0],3,224,224)/255\n",
    "tensorXvalid=tensorXvalid.reshape(tensorXvalid.shape[0],3,224,224)/255\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trainDataset = CustomTensorDataset(tensors=(tensorXtrain, tensorYtrain), transform=testPreprocess)\\ntrainLoader = data_utils.DataLoader(trainDataset, batch_size=batchSize , shuffle=True)\\n\\ntestDataset = CustomTensorDataset(tensors=(tensorXtest, tensorYtest), transform=testPreprocess)\\ntestLoader = data_utils.DataLoader(testDataset, batch_size=batchSize , shuffle=True)\\n\\nvalidDataset = CustomTensorDataset(tensors=(tensorXvalid, tensorYvalid), transform=testPreprocess)\\nvalidLoader = data_utils.DataLoader(validDataset, batch_size=batchSize , shuffle=True)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"trainDataset = CustomTensorDataset(tensors=(tensorXtrain, tensorYtrain), transform=testPreprocess)\n",
    "trainLoader = data_utils.DataLoader(trainDataset, batch_size=batchSize , shuffle=True)\n",
    "\n",
    "testDataset = CustomTensorDataset(tensors=(tensorXtest, tensorYtest), transform=testPreprocess)\n",
    "testLoader = data_utils.DataLoader(testDataset, batch_size=batchSize , shuffle=True)\n",
    "\n",
    "validDataset = CustomTensorDataset(tensors=(tensorXvalid, tensorYvalid), transform=testPreprocess)\n",
    "validLoader = data_utils.DataLoader(validDataset, batch_size=batchSize , shuffle=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootDir = \"group_3\"\n",
    "trainPath = rootDir+'/train'\n",
    "valPath = rootDir+'/valid'\n",
    "testPath = rootDir+'/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms for image pre-processing\n",
    "\n",
    "trainTransform =   transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n",
    "                \n",
    "])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = datasets.ImageFolder(trainPath, transform=transform)\n",
    "valSet = datasets.ImageFolder(valPath, transform=transform)\n",
    "testSet = datasets.ImageFolder(testPath, transform=transform)\n",
    "\n",
    "trainLoader = DataLoader(trainSet, batch_size = batchSize, shuffle=True)\n",
    "validLoader = DataLoader(valSet, batch_size = batchSize)\n",
    "testLoader = DataLoader(testSet, batch_size = batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the VGG pretrained network\n",
    "modelVGG = models.vgg16(pretrained=True)\n",
    "modelVGGFeatureMap=modelVGG.features.to(device)\n",
    "avgPool=modelVGG.avgpool.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No of output classes\n",
    "#learning rate for the optimizer\n",
    "#should we include dropout in fully connected layers\n",
    "#layer architecture for fully connected layers\n",
    "numClass=len(os.listdir(trainPath))\n",
    "lr=0.01\n",
    "dropout=True\n",
    "BN=False\n",
    "activationFn=torch.nn.ReLU()\n",
    "layers=[25088,4096,4096,25]\n",
    "saveModelName=\"bestModelDrop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model=Classifier(25088, numClass,modelVGGFeatureMap,avgPool,layers,activationFn=activationFn,dropout=dropout,BN=BN).to(device).float()\n",
    "optimizer = SGD(model.parameters(), lr=lr,momentum=0.8, weight_decay=5e-4)\n",
    "#optimizer=Adam(model.parameters(),lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5,10,15], gamma=0.1)\n",
    "lossFn=torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.modelVGGFeatureMap.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (modelVGGFeatureMap): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgPool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=4096, out_features=25, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy before training the model on training data was  4.925241864555849\n",
      "The accuracy before training the model on testing data was  2.4\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy before training the model on training data was \",findAccuracy(model,trainLoader))\n",
    "print(\"The accuracy before training the model on testing data was \",findAccuracy(model,testLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training the network\n",
      "\n",
      "Starting epoch no  0\n",
      "Saving the model\n",
      "Loss:  52.089589297771454 Train Accuracy is  90.12019935502785 Valid Accuracy is  88.0\n",
      "\n",
      "Starting epoch no  1\n",
      "Saving the model\n",
      "Loss:  7.327360168099403 Train Accuracy is  97.59601289944298 Valid Accuracy is  92.8\n",
      "\n",
      "Starting epoch no  2\n",
      "Saving the model\n",
      "Loss:  2.092576876282692 Train Accuracy is  99.73614775725594 Valid Accuracy is  99.2\n",
      "\n",
      "Starting epoch no  3\n",
      "Loss:  1.0294190980494022 Train Accuracy is  99.97068308413955 Valid Accuracy is  99.2\n",
      "\n",
      "Starting epoch no  4\n",
      "Loss:  0.5912543199956417 Train Accuracy is  99.97068308413955 Valid Accuracy is  99.2\n",
      "\n",
      "Starting epoch no  5\n",
      "Loss:  0.42855485063046217 Train Accuracy is  99.97068308413955 Valid Accuracy is  99.2\n",
      "\n",
      "Starting epoch no  6\n",
      "Loss:  0.40664856880903244 Train Accuracy is  99.97068308413955 Valid Accuracy is  99.2\n",
      "\n",
      "Starting epoch no  7\n",
      "Loss:  0.38539939373731613 Train Accuracy is  99.97068308413955 Valid Accuracy is  99.2\n",
      "\n",
      "Starting epoch no  8\n",
      "Loss:  0.37470604106783867 Train Accuracy is  99.97068308413955 Valid Accuracy is  99.2\n",
      "\n",
      "Starting epoch no  9\n",
      "Loss:  0.3686225526034832 Train Accuracy is  99.97068308413955 Valid Accuracy is  99.2\n",
      "\n",
      "Starting epoch no  10\n",
      "Loss:  0.3588914591819048 Train Accuracy is  99.97068308413955 Valid Accuracy is  99.2\n",
      "\n",
      "Starting epoch no  11\n",
      "Loss:  0.36717351991683245 Train Accuracy is  99.97068308413955 Valid Accuracy is  99.2\n",
      "\n",
      "Starting epoch no  12\n",
      "Loss:  0.3631798643618822 Train Accuracy is  99.97068308413955 Valid Accuracy is  99.2\n",
      "\n",
      "Starting epoch no  13\n",
      "Loss:  0.3618705989792943 Train Accuracy is  99.97068308413955 Valid Accuracy is  99.2\n",
      "\n",
      "Starting epoch no  14\n",
      "Loss:  0.35234442353248596 Train Accuracy is  99.97068308413955 Valid Accuracy is  99.2\n",
      "\n",
      "Starting epoch no  15\n",
      "Loss:  0.35346141178160906 Train Accuracy is  99.97068308413955 Valid Accuracy is  99.2\n",
      "\n",
      "Starting epoch no  16\n",
      "Loss:  0.3556621205061674 Train Accuracy is  99.97068308413955 Valid Accuracy is  99.2\n",
      "\n",
      "Starting epoch no  17\n",
      "Loss:  0.3539090733975172 Train Accuracy is  99.97068308413955 Valid Accuracy is  99.2\n",
      "\n",
      "Starting epoch no  18\n",
      "Loss:  0.3569133123382926 Train Accuracy is  99.97068308413955 Valid Accuracy is  99.2\n",
      "\n",
      "Starting epoch no  19\n",
      "Loss:  0.35431994358077645 Train Accuracy is  99.97068308413955 Valid Accuracy is  99.2\n",
      "\n",
      "Starting epoch no  20\n",
      "Loss:  0.3518008077517152 Train Accuracy is  99.97068308413955 Valid Accuracy is  99.2\n",
      "\n",
      "Starting epoch no  21\n",
      "Loss:  0.35580676421523094 Train Accuracy is  99.97068308413955 Valid Accuracy is  99.2\n",
      "\n",
      "Starting epoch no  22\n",
      "Loss:  0.3520538955926895 Train Accuracy is  99.97068308413955 Valid Accuracy is  99.2\n",
      "\n",
      "Starting epoch no  23\n",
      "Loss:  0.3570774868130684 Train Accuracy is  99.97068308413955 Valid Accuracy is  99.2\n",
      "\n",
      "Starting epoch no  24\n",
      "Loss:  0.35108810011297464 Train Accuracy is  99.97068308413955 Valid Accuracy is  99.2\n",
      "Training finished in  693.4609298706055 seconds\n"
     ]
    }
   ],
   "source": [
    "epochs=25\n",
    "model,lossList, trainaccuracyList, validaccuracyList=trainModel(model,epochs,returnLoss=True, returnAccuracy=True,saveModelName=saveModelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy after training the model on testing data is  98.4\n",
      "The accuracy after training the model on validation data is  99.2\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy after training the model on testing data is \",findAccuracy(model,testLoader))\n",
    "print(\"The accuracy after training the model on validation data is \",findAccuracy(model, validLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lossList)\n",
    "plt.xlabel(\"epoch number\")\n",
    "plt.ylabel(\"Total Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trainaccuracyList)\n",
    "plt.plot(validaccuracyList)\n",
    "plt.xlabel(\"epoch number\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"training accuracy\", \"validation accuracy\"], loc =\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
